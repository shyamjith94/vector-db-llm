{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764bca91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Documents\\GitrRepo\\vector-db-llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1288d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the pdf\n",
    "\n",
    "from xml.dom.minidom import Document\n",
    "\n",
    "\n",
    "def read_pdf(folder_path):\n",
    "    try:\n",
    "        if not os.path.exists(folder_path):\n",
    "            raise FileNotFoundError(f\"The folder {folder_path} does not exist.\")\n",
    "        all_document=[]\n",
    "        pdf_files = (Path(folder_path)).glob(\"**/*.pdf\")\n",
    "        pdf_files = list(pdf_files)  # Convert the generator to a list\n",
    "        \n",
    "        print(f\"Number of file read from dir {len(list(pdf_files))}\",  end=\"\\n\")\n",
    "        for pdf_file in pdf_files:\n",
    "            print(\"start processing file\",pdf_file)\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            print(\"Document length before split\",len(documents), end=\"\\n\")\n",
    "            # add some more meta data\n",
    "            for doc in documents:\n",
    "                doc.metadata[\"source\"] = str(pdf_file)\n",
    "                doc.metadata[\"type\"] = \"pdf\"\n",
    "            all_document.extend(documents)\n",
    "        print(f\"Number of document process from dir{len(all_document)}\",  end=\"\\n\")\n",
    "        return all_document\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82ac2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of file read from dir 1\n",
      "start processing file ..\\data\\textfile\\budget_speech.pdf\n",
      "Document length before split 58\n",
      "Number of document process from dir58\n"
     ]
    }
   ],
   "source": [
    "all_documents = read_pdf(\"../data/textfile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eba5ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking and splitting document\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        separators=[\"\\n\",\"\\n\\n\", \" \", \"\"],\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        )\n",
    "    splitted_docs = splitter.split_documents(documents)\n",
    "\n",
    "    print(f\"Number of document {len(documents)} after split {len(splitted_docs)}\",  end=\"\\n\\n\")\n",
    "\n",
    "    if splitted_docs:\n",
    "        print(\"Example of splitted document content\\n\", splitted_docs[0].page_content[:200], end=\"\\n\\n\")\n",
    "        print(\"Example of splitted document metadata\\n\", splitted_docs[0].metadata, end=\"\\n\\n\")\n",
    "    return splitted_docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84a6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document 58 after split 122\n",
      "\n",
      "Example of splitted document content\n",
      " GOVERNMENT OF INDIA\n",
      "BUDGET 2023-2024\n",
      "SPEECH\n",
      "OF\n",
      "NIRMALA SITHARAMAN\n",
      "MINISTER OF FINANCE\n",
      "February 1,  2023\n",
      "\n",
      "Example of splitted document metadata\n",
      " {'producer': 'Adobe Acrobat Pro 10.1.16', 'creator': 'Adobe Acrobat Pro 10.1.16', 'creationdate': '2023-02-01T05:28:04+05:30', 'moddate': '2023-02-01T08:28:21+05:30', 'title': '', 'source': '..\\\\data\\\\textfile\\\\budget_speech.pdf', 'total_pages': 58, 'page': 0, 'page_label': '1', 'type': 'pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721f0ea3",
   "metadata": {},
   "source": [
    "Embedding Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b107ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import chromadb.config\n",
    "import uuid\n",
    "from typing import List, Dict, Tuple, Any, Optional\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2a508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingVectorDB:\n",
    "    def __init__(self, model_name:str=\"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    def _load_model(self):\n",
    "        \"\"\"\n",
    "        Load the embedding model based on the specified model name.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"Model name \", self.model_name)\n",
    "            self.model =SentenceTransformer(self.model_name)\n",
    "            if(self.model):\n",
    "                print(f\"Model loaded {self.model_name} dimension is {self.get_embedding_dimension()}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading the model: {e}\")\n",
    "\n",
    "    def generate_embedding(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts.\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model is not loaded. Please load the model before generating embeddings.\")\n",
    "        try:\n",
    "            embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "            return embeddings\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while generating embeddings: {e}\")\n",
    "            return np.array([])\n",
    "        \n",
    "    def get_embedding_dimension(self) -> int:\n",
    "        \"\"\"\n",
    "        Get the dimension of the embeddings generated by the model.\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model is not loaded. Please load the model to get embedding dimension.\")\n",
    "        return self.model.get_sentence_embedding_dimension()   \n",
    "     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce6cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name  all-MiniLM-L6-v2\n",
      "Model loaded all-MiniLM-L6-v2 dimension is 384.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingVectorDB at 0x18195604680>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_manager = EmbeddingVectorDB()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf06a47",
   "metadata": {},
   "source": [
    "Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b804a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from importlib import metadata\n",
    "\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self,collection_name:str=\"pdf_collection\", persist_directory:str=\"../data/vector_store\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.clint = None\n",
    "        self.collection = None\n",
    "        self._initialize_vector_store()\n",
    "\n",
    "    def _initialize_vector_store(self):\n",
    "        try:\n",
    "            # create directory if not exists and chromadb persistent client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # create or get the collection\n",
    "            self.collection = self.client.get_or_create_collection(name=self.collection_name,metadata={\n",
    "                \"description\":\"PDF document embedding for RAG\"\n",
    "            })\n",
    "            \n",
    "            print(f\"Vector store initialized with collection '{self.collection_name}' at '{self.persist_directory}'\\n\\n\")\n",
    "            print(f\"Number of vectors in the collection: {self.collection.count()}\\n\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while initializing the vector store: {e}\")\n",
    "            \n",
    "    def add_documents(self, documents: List[any], embedding:np.ndarray):\n",
    "        try:\n",
    "            len_docs = len(documents)\n",
    "            len_embedding = len(embedding)\n",
    "            \n",
    "            if(len_docs != len_embedding):\n",
    "               raise ValueError(f\"The number of documents {len_docs} must match the number of embeddings {len_embedding}. \")\n",
    "\n",
    "            print(f\"Adding {len_docs} documents to the vector store...\")\n",
    "\n",
    "            ids = []\n",
    "            metadatas = []\n",
    "            doc_texts = []\n",
    "            embedding_list = []\n",
    "\n",
    "            for i, (doc, embed) in enumerate(zip(documents, embedding)):\n",
    "                doc_id = f\"{uuid.uuid4().hex[:8]}_{i}\"\n",
    "\n",
    "                # meta data\n",
    "                ids.append(doc_id)\n",
    "                meta_data = dict(doc.metadata)\n",
    "                meta_data[\"doc_index\"] = i\n",
    "                meta_data[\"content_length\"] = len(doc.page_content)\n",
    "                metadatas.append(meta_data)\n",
    "\n",
    "                # doc\n",
    "                doc_texts.append(doc.page_content)\n",
    "\n",
    "                # embedding\n",
    "                embedding_list.append(embed.tolist())\n",
    "\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                documents=doc_texts,\n",
    "                metadatas=metadatas,\n",
    "                embeddings=embedding_list,\n",
    "            )\n",
    "            \n",
    "            print(f\"Successfully added {len_docs} documents to the vector store. Total vectors now: {self.collection.count()}\\n\\n\")\n",
    "           \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while adding documents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e69d47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized with collection 'pdf_collection' at '../data/vector_store'\n",
      "\n",
      "\n",
      "Number of vectors in the collection: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x181fdcdc2f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_storage = VectorStore()\n",
    "vector_storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f5886b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GOVERNMENT OF INDIA\\nBUDGET 2023-2024\\nSPEECH\\nOF\\nNIRMALA SITHARAMAN\\nMINISTER OF FINANCE\\nFebruary 1,  2023',\n",
       " 'CONTENTS \\nPART-A \\n Page No. \\n\\uf0b7 Introduction 1 \\n\\uf0b7 Achievements since 2014: Leaving no one behind 2 \\n\\uf0b7 Vision for Amrit Kaal – an empowered and inclusive economy 3 \\n\\uf0b7 Priorities of this Budget 5 \\ni. Inclusive Development  \\nii. Reaching the Last Mile \\niii. Infrastructure and Investment \\niv. Unleashing the Potential \\nv. Green Growth \\nvi. Youth Power  \\nvii. Financial Sector \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\\uf0b7 Fiscal Management \\n24 \\nPART B \\n  \\nIndirect Taxes 27 \\n\\uf0b7 Green Mobility  \\n\\uf0b7 Electronics   \\n\\uf0b7 Electrical   \\n\\uf0b7 Chemicals and Petrochemicals   \\n\\uf0b7 Marine products  \\n\\uf0b7 Lab Grown Diamonds  \\n\\uf0b7 Precious Metals  \\n\\uf0b7 Metals  \\n\\uf0b7 Compounded Rubber  \\n\\uf0b7 Cigarettes  \\n  \\nDirect Taxes 30 \\n\\uf0b7 MSMEs and Professionals   \\n\\uf0b7 Cooperation  \\n\\uf0b7 Start-Ups  \\n\\uf0b7 Appeals  \\n\\uf0b7 Better targeting of tax concessions  \\n\\uf0b7 Rationalisation  \\n\\uf0b7 Others  \\n\\uf0b7 Personal Income Tax  \\n  \\nAnnexures 35 \\n\\uf0b7 Annexure to Part B of the Budget Speech 2023-24 \\ni. Amendments relating to Direct Taxes \\nii. Amendments relating to Indirect Taxes',\n",
       " 'Budget 2023-2024 \\n \\nSpeech of \\nNirmala Sitharaman \\nMinister of Finance \\nFebruary 1, 2023 \\nHon’ble Speaker,  \\n I present the Budget for 2023-24. This is the first Budget in Amrit \\nKaal. \\nIntroduction \\n1. This Budget hopes to build on the foundation laid in the previous \\nBudget, and the blueprint drawn for India@100. We envision a prosperous \\nand inclusive India, in which the fruits of development reach all regions and \\ncitizens, especially our youth, women, farmers, OBCs, Scheduled Castes and \\nScheduled Tribes.  \\n2. In the 75 th year of our Independence, the world has recognised the \\nIndian economy as a ‘bright star’. Our current year’s economic growth is \\nestimated to be at 7 per cent. It is notable that this is the highest among all \\nthe major economies. This is in spite of the massive slowdown globally \\ncaused by Covid-19 and a war. The Indian economy is therefore on the right \\ntrack, and despite a time of challenges, heading towards a bright future.',\n",
       " 'caused by Covid-19 and a war. The Indian economy is therefore on the right \\ntrack, and despite a time of challenges, heading towards a bright future.  \\n3. Today as Indians stands with their head held high, and the world \\nappreciates India’s achievements and successes, we are sure that elders \\nwho had fought for India’s independence, will with joy, bless us our \\nendeavors going forward. \\nResilience amidst multiple crises \\n4. Our focus on wide-ranging reforms and sound policies, implemented \\nthrough Sabka Prayas  resulting in Jan Bhagidari  and targeted support to \\nthose in need, helped us perform well in trying times. India’s rising global',\n",
       " '2 \\n \\n \\n \\nprofile is because of several accomplishments: unique world class digital \\npublic infrastructure, e.g., Aadhaar, Co-Win and UPI; Covid vaccination drive \\nin unparalleled scale and speed; proactive role in frontier areas such as \\nachieving the climate related goals, mission LiFE, and National Hydrogen \\nMission.  \\n5. During the Covid-19 pandemic, we ensured that no one goes to bed \\nhungry, with a scheme to supply free food grains to over 80 crore persons \\nfor 28 months. Continuing our commitment to ensure food and nutritional \\nsecurity, we are implementing, from 1 st January 2023, a scheme to supply \\nfree food grain to all Antyodaya and priority households for the next one \\nyear, under PM Garib Kalyan Anna Yojana (PMGKAY). The entire \\nexpenditure of about ` 2 lakh crore will be borne by the Central \\nGovernment. \\nG20 Presidency: Steering the global agenda through challenges \\n6. In these times of global challenges, the G20 Presidency gives us a']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract page content for from chunks\n",
    "\n",
    "text = [doc.page_content for doc in chunks]\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3dbea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [00:07<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# generate embedding\n",
    "\n",
    "embedding = embedding_manager.generate_embedding(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de76050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 122 documents to the vector store...\n",
      "Successfully added 122 documents to the vector store. Total vectors now: 122\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_storage.add_documents(chunks, embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c21f80",
   "metadata": {},
   "source": [
    "#RAG retrieval pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eb3f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from turtle import distance\n",
    "\n",
    "\n",
    "class RAGRetrievalPipeline:\n",
    "    \"\"\"\n",
    "    handle query based retrieval from vector store\n",
    "    \"\"\"\n",
    "    def __init__(self, vector_storage:VectorStore, embedding_manager:EmbeddingVectorDB)-> List[Dict[str, Any]]:\n",
    "        self.vector_store_control = vector_storage\n",
    "        self.embedding_control = embedding_manager\n",
    "\n",
    "    def retrieve_from_store(self, query: str, top_k:int = 5, score_threshold:float=0.0):\n",
    "        \"\"\"\n",
    "        retrieve information based on user query\n",
    "        \"\"\"\n",
    "\n",
    "        # user query convert to embedding\n",
    "        query_embedding = self.embedding_control.generate_embedding([query])[0]\n",
    "\n",
    "        # query in  vector db\n",
    "\n",
    "        result = self.vector_store_control.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=top_k,\n",
    "            )\n",
    "        if result[\"documents\"] and result[\"documents\"][0]:\n",
    "            documents = result[\"documents\"][0]\n",
    "            metadatas = result[\"metadatas\"][0]\n",
    "            distances = result[\"distances\"][0]\n",
    "            ids = result[\"ids\"][0]\n",
    "\n",
    "        \n",
    "        retrieved_docs = []\n",
    "        for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "\n",
    "            # convert distance into similarity score chromo DB use cosine distance \n",
    "            similarity_score = 1-distance\n",
    "\n",
    "            if similarity_score >=score_threshold:\n",
    "                retrieved_docs.append({\n",
    "                    \"id\":doc_id,\n",
    "                    \"content\":document,\n",
    "                    \"metadata\":metadata,\n",
    "                    \"similarity_score\":similarity_score,\n",
    "                    \"distance\":distance,\n",
    "                    \"rank\":i+1,\n",
    "                })\n",
    "        print(f'Retrieved documents len {len(retrieved_docs)} ')\n",
    "        print('documents are -')\n",
    "        print('-'*10)\n",
    "        print(retrieved_docs)\n",
    "\n",
    "        return retrieved_docs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "703ed462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved documents len 2 \n",
      "documents are -\n",
      "----------\n",
      "[{'id': 'bae88ee1_2', 'content': 'Budget 2023-2024 \\n \\nSpeech of \\nNirmala Sitharaman \\nMinister of Finance \\nFebruary 1, 2023 \\nHon’ble Speaker,  \\n I present the Budget for 2023-24. This is the first Budget in Amrit \\nKaal. \\nIntroduction \\n1. This Budget hopes to build on the foundation laid in the previous \\nBudget, and the blueprint drawn for India@100. We envision a prosperous \\nand inclusive India, in which the fruits of development reach all regions and \\ncitizens, especially our youth, women, farmers, OBCs, Scheduled Castes and \\nScheduled Tribes.  \\n2. In the 75 th year of our Independence, the world has recognised the \\nIndian economy as a ‘bright star’. Our current year’s economic growth is \\nestimated to be at 7 per cent. It is notable that this is the highest among all \\nthe major economies. This is in spite of the massive slowdown globally \\ncaused by Covid-19 and a war. The Indian economy is therefore on the right \\ntrack, and despite a time of challenges, heading towards a bright future.', 'metadata': {'type': 'pdf', 'doc_index': 2, 'page_label': '5', 'page': 4, 'creator': 'Adobe Acrobat Pro 10.1.16', 'title': '', 'content_length': 966, 'producer': 'Adobe Acrobat Pro 10.1.16', 'creationdate': '2023-02-01T05:28:04+05:30', 'moddate': '2023-02-01T08:28:21+05:30', 'total_pages': 58, 'source': '..\\\\data\\\\textfile\\\\budget_speech.pdf'}, 'similarity_score': 0.16165411472320557, 'distance': 0.8383458852767944, 'rank': 1}, {'id': '5e01b8d2_0', 'content': 'GOVERNMENT OF INDIA\\nBUDGET 2023-2024\\nSPEECH\\nOF\\nNIRMALA SITHARAMAN\\nMINISTER OF FINANCE\\nFebruary 1,  2023', 'metadata': {'doc_index': 0, 'creationdate': '2023-02-01T05:28:04+05:30', 'page_label': '1', 'source': '..\\\\data\\\\textfile\\\\budget_speech.pdf', 'creator': 'Adobe Acrobat Pro 10.1.16', 'page': 0, 'title': '', 'moddate': '2023-02-01T08:28:21+05:30', 'type': 'pdf', 'producer': 'Adobe Acrobat Pro 10.1.16', 'total_pages': 58, 'content_length': 103}, 'similarity_score': 0.03242141008377075, 'distance': 0.9675785899162292, 'rank': 2}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'bae88ee1_2',\n",
       "  'content': 'Budget 2023-2024 \\n \\nSpeech of \\nNirmala Sitharaman \\nMinister of Finance \\nFebruary 1, 2023 \\nHon’ble Speaker,  \\n I present the Budget for 2023-24. This is the first Budget in Amrit \\nKaal. \\nIntroduction \\n1. This Budget hopes to build on the foundation laid in the previous \\nBudget, and the blueprint drawn for India@100. We envision a prosperous \\nand inclusive India, in which the fruits of development reach all regions and \\ncitizens, especially our youth, women, farmers, OBCs, Scheduled Castes and \\nScheduled Tribes.  \\n2. In the 75 th year of our Independence, the world has recognised the \\nIndian economy as a ‘bright star’. Our current year’s economic growth is \\nestimated to be at 7 per cent. It is notable that this is the highest among all \\nthe major economies. This is in spite of the massive slowdown globally \\ncaused by Covid-19 and a war. The Indian economy is therefore on the right \\ntrack, and despite a time of challenges, heading towards a bright future.',\n",
       "  'metadata': {'type': 'pdf',\n",
       "   'doc_index': 2,\n",
       "   'page_label': '5',\n",
       "   'page': 4,\n",
       "   'creator': 'Adobe Acrobat Pro 10.1.16',\n",
       "   'title': '',\n",
       "   'content_length': 966,\n",
       "   'producer': 'Adobe Acrobat Pro 10.1.16',\n",
       "   'creationdate': '2023-02-01T05:28:04+05:30',\n",
       "   'moddate': '2023-02-01T08:28:21+05:30',\n",
       "   'total_pages': 58,\n",
       "   'source': '..\\\\data\\\\textfile\\\\budget_speech.pdf'},\n",
       "  'similarity_score': 0.16165411472320557,\n",
       "  'distance': 0.8383458852767944,\n",
       "  'rank': 1},\n",
       " {'id': '5e01b8d2_0',\n",
       "  'content': 'GOVERNMENT OF INDIA\\nBUDGET 2023-2024\\nSPEECH\\nOF\\nNIRMALA SITHARAMAN\\nMINISTER OF FINANCE\\nFebruary 1,  2023',\n",
       "  'metadata': {'doc_index': 0,\n",
       "   'creationdate': '2023-02-01T05:28:04+05:30',\n",
       "   'page_label': '1',\n",
       "   'source': '..\\\\data\\\\textfile\\\\budget_speech.pdf',\n",
       "   'creator': 'Adobe Acrobat Pro 10.1.16',\n",
       "   'page': 0,\n",
       "   'title': '',\n",
       "   'moddate': '2023-02-01T08:28:21+05:30',\n",
       "   'type': 'pdf',\n",
       "   'producer': 'Adobe Acrobat Pro 10.1.16',\n",
       "   'total_pages': 58,\n",
       "   'content_length': 103},\n",
       "  'similarity_score': 0.03242141008377075,\n",
       "  'distance': 0.9675785899162292,\n",
       "  'rank': 2}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retrieval_pipeline = RAGRetrievalPipeline(vector_storage=vector_storage, embedding_manager=embedding_manager)\n",
    "rag_retrieval_pipeline.retrieve_from_store(\"2023-2024 budget details especially how it effect in Electronics industry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300c48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
